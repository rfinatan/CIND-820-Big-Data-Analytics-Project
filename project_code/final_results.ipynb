{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIp1Hpu8E1VR"
      },
      "outputs": [],
      "source": [
        "#initialize dependencies\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# --- SECTION 1: INITIAL ANALYSIS ---\n",
        "\n",
        "# 1.1 - Fundamnental Data Analysis\n",
        "\n",
        "#initial data import\n",
        "occurence_raw = pd.read_csv('MARSISdb_MDOTW_VW_OCCURRENCE_PUBLIC.csv')\n",
        "vessel_raw = pd.read_csv('MARSISdb_MDOTW_VW_OCCURRENCE_VESSEL_PUBLIC.csv')\n",
        "\n",
        "#merge the raw data sets\n",
        "marsis_raw = pd.merge(\n",
        "    occurence_raw,\n",
        "    vessel_raw,\n",
        "    how = 'inner',\n",
        "    left_on = 'OccID',\n",
        "    right_on = 'OccID')\n",
        "\n",
        "#view structure of the dataset\n",
        "marsis_raw.info()\n",
        "\n",
        "#view attribute data types\n",
        "marsis_raw.dtypes\n",
        "\n",
        "#view structure of combined data frame using pandas\n",
        "pd.DataFrame.describe(marsis_raw)\n",
        "\n",
        "#create a dataframe of the datatypes in the dataset\n",
        "marsis_data_types = marsis_raw.dtypes.to_frame('dtypes').reset_index()\n",
        "marsis_data_types.rename(columns = {'index':'raw_attribute'}, inplace = True)\n",
        "\n",
        "#compare identified data types to provided data dictionary\n",
        "marsis_dd = pd.read_csv(\"MARSISdb-dd-processed.csv\")\n",
        "marsis_dd = marsis_dd[marsis_dd.table_name == 'MDOTW_VW_OCCURRENCE_PUBLIC']\n",
        "data_type_comparison = pd.merge(\n",
        "    marsis_data_types,\n",
        "    marsis_dd,\n",
        "    how = \"inner\",\n",
        "    left_on = \"raw_attribute\",\n",
        "    right_on = \"column_name\"\n",
        ")\n",
        "\n",
        "# --- SECTION 2: DATA CLEANING ---\n",
        "\n",
        "# 2.1 - Basic Data Cleaning, Primitive Dimensionality Reduction\n",
        "\n",
        "#remove attributes with no values\n",
        "marsis_no_nas = marsis_raw.copy(deep=True)\n",
        "marsis_no_nas.dropna(how='all', axis='columns', inplace=True)\n",
        "\n",
        "#some columns are duplicated in English and French \n",
        "#only require the English attribute variants, remove the French \n",
        "marsis_eng_only = marsis_no_nas.copy(deep=True)\n",
        "marsis_eng_only.drop(marsis_eng_only.filter(regex='DisplayFre').columns, axis=1, inplace=True)\n",
        "\n",
        "#there remain many columns with high percentage of NAs in the record counts\n",
        "#determine each column's percentage of NA records\n",
        "nas_percentage = (marsis_eng_only.isna().mean().round(2) * 100).to_frame(name = 'percentage')\n",
        "#determine the columns with high percentage of NAs, more specifically greater than 80% NAs\n",
        "nas_80_percent = nas_percentage.loc[nas_percentage['percentage'] > 80]\n",
        "\n",
        "#visualize distribution of NA percentages\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.hist(nas_percentage['percentage'], bins = 20)\n",
        "plt.xticks(np.arange(0, max(nas_percentage['percentage']), 5))\n",
        "plt.title('Number of Attributes and Their % of NA Records')\n",
        "plt.xlabel('Percentage of Attribute NA Records')\n",
        "plt.ylabel('Number of Attributes')\n",
        "plt.show()\n",
        "\n",
        "#create a list of the attributes that have higher than 80% NA records\n",
        "nas_80_percent.reset_index(inplace=True)\n",
        "nas_80_percent_list = list(nas_80_percent['index'])\n",
        "\n",
        "#remove the attributes with more than 80% NA records\n",
        "marsis_no_nas_80 = marsis_eng_only.drop(columns = nas_80_percent_list)\n",
        "\n",
        "#there are also columns that have NA values masked as NULL strings\n",
        "#identify the columns with all NULL string records\n",
        "marsis_nulls = marsis_no_nas_80.loc[: , ((marsis_no_nas_80 == 'Null').any())]\n",
        "marsis_nulls = list(marsis_nulls.columns)\n",
        "\n",
        "#remove the columns with all NULL string records\n",
        "marsis_basic_cleaned = marsis_no_nas_80.drop(columns = marsis_nulls)\n",
        "\n",
        "# 2.2 - Contextual Data Cleaning\n",
        "\n",
        "#given the context of the study, the area of focus is occurrences resulting in deaths\n",
        "marsis_processed = marsis_basic_cleaned.copy(deep=True)\n",
        "\n",
        "#many occurrences ending in a death have the same OccID and OccNo\n",
        "#this is because each individual phase of the recorded occurrence is filed under the same OccID and OccNo\n",
        "#to identify the unique cases of deadly occurrences, duplicate OccIDs must be dropped, and only the most recent is kept\n",
        "#the most recent OccID is kept because it houses the final investigative data leading to the occurrence's result\n",
        "\n",
        "#all OccDate instances have a 12:00:00 timestamp applied to them, whether actual or not\n",
        "#strip timestamp from OccDate attribute records\n",
        "marsis_processed['OccDate'] = marsis_processed['OccDate'].str.replace(' 12:00:00 AM', '')\n",
        "\n",
        "#some OccTime instances have NA values; assume 00:00:00 timestamp given lack of information\n",
        "marsis_processed['OccTime'] = marsis_processed['OccTime'].fillna('00:00:00')\n",
        "\n",
        "#concatenate date and time attributes\n",
        "marsis_processed['OccDateTime'] = marsis_processed['OccDate'] + ' ' + marsis_processed['OccTime']\n",
        "\n",
        "#ensure date attributes are of dtype 'datetime'\n",
        "marsis_processed['OccDateTime'] = pd.to_datetime(marsis_processed['OccDateTime'])\n",
        "\n",
        "#drop duplicate OccId instances, but keep latest OccId instance\n",
        "marsis_processed_unique = marsis_processed.sort_values('OccDateTime').drop_duplicates('OccID', keep = 'last')\n",
        "\n",
        "# 2.2.1 - Removing Duplicate Attributes and Keeping Integer Encoding\n",
        "\n",
        "#some attributes are duplicates of other attributes, but only exist for data classification purposes\n",
        "#the attributes under study already have been encoded via integer encoding\n",
        "#remove attributes that have an equivalent attribute, but keep the attribute that has integer encoding\n",
        "\n",
        "#OccID and OccNo represent the same occurrence, but only one is necessary for classification\n",
        "marsis_processed = marsis_processed_unique.drop(columns = 'OccNo')\n",
        "\n",
        "#OccClassID and OccClassDisplayEng are identical, but only OccClassID is integer encoded\n",
        "marsis_processed = marsis_processed.drop(columns = 'OccClassDisplayEng')\n",
        "\n",
        "#the same duplicate attribute (integer encoding vs non-encoded) scenario applies to all attributes ending in '[...]DisplayEng'\n",
        "marsis_processed.drop(marsis_processed.filter(regex='DisplayEng').columns, axis=1, inplace=True)\n",
        "\n",
        "# 2.2.2 - Removing Attributes Unfit for Encoding\n",
        "\n",
        "#the dataset contains a set of attributes too varied or complex in their contents to be encoded\n",
        "#remove attributes unfit for encoding \n",
        "unfit_for_encoding = ['IICName', 'Summary', 'NearestLocationDescription', 'OccDate', 'OccTime', 'OccDateTime', 'WindDirection']\n",
        "\n",
        "marsis_processed = marsis_processed.drop(columns = unfit_for_encoding)\n",
        "\n",
        "# 2.2.3 - Removing Attributes with Low Variance\n",
        "\n",
        "#determine variance of records per column in dataset\n",
        "attribute_variance = marsis_processed.var(numeric_only = True).to_frame()\n",
        "\n",
        "#remove low variance attributes from dataset\n",
        "low_variance_attributes = ['IncludedInDailyEnum', 'MajorChangesIncludedInDaily', 'LatEnum', 'LongEnum']\n",
        "\n",
        "marsis_processed = marsis_processed.drop(columns = low_variance_attributes)\n",
        "\n",
        "# 2.2.4 - Removing Attributes Irrelevant to Hypothesis\n",
        "\n",
        "#the dataset contains a set of attributes that are administrative, indicating when the report was released, filed, closed, and reported on by the Ministry of Transportation\n",
        "#these attributes would not be useful in predicting a test dataset because they only serve for reporting or record identification purposes\n",
        "#remove administrative attributes\n",
        "administrative_attributes = ['ReleasedDate', 'OccClosedDate', 'EntryDate', 'ReportedDate', 'ReportedByID', 'OccID', 'TimeZoneID']\n",
        "\n",
        "marsis_processed = marsis_processed.drop(columns = administrative_attributes)\n",
        "\n",
        "\n",
        "# --- SECTION 3: Target Attribute Creation and Building Train, Validation, Testing Sets\n",
        "\n",
        "# 3.1 - Target Variable Creation\n",
        "\n",
        "#to create a target variable, determine the number of levels required for fatality classification\n",
        "\n",
        "#store distribution of TotalDeaths\n",
        "marsis_deadly = marsis_processed[marsis_processed['TotalDeaths'] > 0]\n",
        "\n",
        "#the range of deaths is between 0, and 84\n",
        "#most deaths are distributed between 0 and 5\n",
        "plt.hist(marsis_deadly['TotalDeaths'], bins = 100)\n",
        "plt.xticks(np.arange(0, max(marsis_deadly['TotalDeaths']), 1))\n",
        "plt.title('Distribution of TotalDeaths')\n",
        "plt.xlabel('Number of Deaths per Occurrence')\n",
        "plt.ylabel('Number of Occurrences')\n",
        "plt.xlim(0, 10)\n",
        "plt.show()\n",
        "\n",
        "#the average death count for fatal occurrences is 1.45 deaths\n",
        "import statistics\n",
        "statistics.mean(marsis_deadly['TotalDeaths'])\n",
        "\n",
        "#since the number of average deaths is less than 2, the target variable death classifier will be a binary Yes or No\n",
        "#add the target variable OccDeathClassID with the classification 1 = yes, 0 = no\n",
        "\n",
        "marsis_processed['OccDeathClassID'] = np.where(marsis_processed['TotalDeaths']!= 0, 1, 0)\n",
        "\n",
        "# 3.2 - Data Splitting\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#create input array (excluding target variable and its direct attribute dependents)\n",
        "x = marsis_processed.loc[:, ~marsis_processed.columns.isin(['OccDeathClassID', 'TotalDeaths', 'OccClassID', 'ImoClassLevelID'])]\n",
        "\n",
        "#create output array (including target variable)\n",
        "y = marsis_processed['OccDeathClassID'].to_frame()\n",
        "\n",
        "#split input and output subsets with sklearn.model_selection.train_test_split() function call\n",
        "#NOTE: the processed dataset is imbalanced as it contains a significant number of records that belong to the OccDeathClassID 0 class\n",
        "#NOTE: recommended to stratify splits to have the same ratio of OccDeathClassID class records in training and testing sets\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x, y, \n",
        "    train_size = 0.7, \n",
        "    test_size = 0.3, \n",
        "    #random_state = 4,\n",
        "    stratify = y)\n",
        "\n",
        "#verify proportionality of stratification in output array\n",
        "y_train.dtypes\n",
        "stratified_y_train = len(y_train[y_train['OccDeathClassID'] == 1]) / len(y_train)\n",
        "print(stratified_y_train)\n",
        "\n",
        "stratified_y_test = len(y_test[y_test['OccDeathClassID'] == 1]) / len(y_test)\n",
        "print(stratified_y_test)\n",
        "\n",
        "# --- SECTION 4: FORMAL DIMENSIONALITY REDUCTION ---\n",
        "\n",
        "import xgboost\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import sklearn.model_selection\n",
        "from matplotlib import pyplot\n",
        "from math import sqrt\n",
        "\n",
        "# 4.1 - Removing Attributes with High Correlations\n",
        "\n",
        "#verify if there are attributes that are too closely correlated and are dependents of the target variable\n",
        "attribute_correlation = marsis_processed.corr()\n",
        "sns.heatmap(marsis_processed.corr(), fmt='.2g',cmap= 'coolwarm')\n",
        "\n",
        "#only two attributes are highly correlated: 'OccClassID' and 'TotalDeaths', which have already been removed from the training and test sets\n",
        "\n",
        "# 4.2 - Dimensionality Reduction by Random Forests Ensemble\n",
        "\n",
        "#given the dataset is very unbalanced between occurrences that have deaths and those that do not, create a parameter that accounts for imbalance\n",
        "#with XGBRFClassifier(), pass scale_pos_weight = x, where x is the total_negative_examples / total_positive_examples\n",
        "\n",
        "#use tweaking param to adjust scale_pos_weight impact on False Positive and False Negative results\n",
        "tweaking_param = 0.45\n",
        "estimate = ((len(y_train[y_train['OccDeathClassID'] == 0])) / (len(y_train[y_train['OccDeathClassID'] == 1]))) * tweaking_param\n",
        "\n",
        "#define the random forest ensembles model\n",
        "heuristic_parameter = sqrt(len(marsis_processed.columns)) / len(marsis_processed.columns)\n",
        "model = xgboost.XGBRFClassifier(n_estimators = 100, subsample = 0.8, colsample_bynode = heuristic_parameter, scale_pos_weight = estimate)\n",
        "\n",
        "#evaluate the model using repeated k-fold cross validation, with three repeats and 10 folds\n",
        "cv = sklearn.model_selection.RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "#evaluate the model and collect the scores\n",
        "n_scores = sklearn.model_selection.cross_val_score(model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\n",
        "#evaluate model accuracy by taking the mean of the cross validation scores, recording its standard deviation\n",
        "print('Mean Accuracy: %.2f (%.2f)' % (np.mean(n_scores), np.std(n_scores)))\n",
        "\n",
        "#fit the random forests model to the training data\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "#store feature importance\n",
        "feature_important = model.get_booster().get_score(importance_type='gain')\n",
        "keys = list(feature_important.keys())\n",
        "values = list(feature_important.values())\n",
        "\n",
        "feature_importance_df = pd.DataFrame(data=values, index=keys, columns=[\"score\"])\n",
        "\n",
        "#visualize feature importance\n",
        "xgboost.plot_importance(model, title = 'Top 15 Most Important Features in Fatality Occurrences', max_num_features = 15)\n",
        "pyplot.show()\n",
        "\n",
        "# --- SECTION 5: MODEL BUILDING AND MODEL COMPARISONS ---\n",
        "\n",
        "# 5.1 - Continuation of Random Forests Ensemble, Model Building and Evaluation\n",
        "\n",
        "#make predictions for test data and evaluate\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "\n",
        "#test and pred results\n",
        "#accuracy score\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "\n",
        "#classification report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "results_comparison = x_test.assign(target = y_test.values, prediction = y_pred)\n",
        "\n",
        "#visualize test and pred results\n",
        "disp = sklearn.metrics.ConfusionMatrixDisplay.from_predictions(\n",
        "    y_test,\n",
        "    y_pred,\n",
        "    display_labels= ['Not Deadly', 'Deadly'])\n",
        "disp.ax_.set_title('Confusion Matrix for Random Forests')\n",
        "plt.show()\n",
        "\n",
        "#visualize ROC AUC\n",
        "fpr, tpr, _ = sklearn.metrics.roc_curve(y_test, y_pred)\n",
        "auc = sklearn.metrics.roc_auc_score(y_test, y_pred)\n",
        "\n",
        "plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.legend(loc=4)\n",
        "plt.suptitle('ROC Curves for Weighted Random Forest')\n",
        "plt.show()\n",
        "\n",
        "#save results for iterative plotting\n",
        "result_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc'])\n",
        "\n",
        "result_table = result_table.append({'classifiers':'Weighted Random Forest',\n",
        "                                    'fpr':fpr, \n",
        "                                    'tpr':tpr, \n",
        "                                    'auc':auc}, ignore_index=True)\n",
        "\n",
        "# 5.1.1 - Redefine the Model's Optimal Weighting using Grid Search\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#define grid weights and parameters\n",
        "weights = [0.1, 0.25, 0.5, 0.75, 1, 10, 25, 50, 75, 100]\n",
        "param_grid = dict(scale_pos_weight=weights)\n",
        "\n",
        "#evaluate the model using repeated k-fold cross validation, with three repeats and 10 folds\n",
        "cv = sklearn.model_selection.RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "#define grid search execution\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='roc_auc')\n",
        "grid_result = grid.fit(x_train, y_train)\n",
        "\n",
        "#report the best configuration\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "\n",
        "# report all configurations\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
        "    \n",
        "#redefine the model given best defined weighting\n",
        "model = xgboost.XGBRFClassifier(n_estimators = 100, subsample = 0.8, scale_pos_weight = (list(grid_result.best_params_.values())[0]))\n",
        "\n",
        "#fit the random forests model to the training data\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "#make predictions for test data and evaluate\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "\n",
        "#test and pred results\n",
        "#accuracy score\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "\n",
        "#classification report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "results_comparison = x_test.assign(target = y_test.values, prediction = y_pred)\n",
        "\n",
        "#visualize test and pred results\n",
        "disp = sklearn.metrics.ConfusionMatrixDisplay.from_predictions(\n",
        "    y_test,\n",
        "    y_pred,\n",
        "    display_labels= ['Not Deadly', 'Deadly'])\n",
        "disp.ax_.set_title('Confusion Matrix for Weight Optimized Random Forests')\n",
        "plt.show()\n",
        "\n",
        "#visualize ROC AUC\n",
        "fpr, tpr, _ = sklearn.metrics.roc_curve(y_test, y_pred)\n",
        "auc = sklearn.metrics.roc_auc_score(y_test, y_pred)\n",
        "\n",
        "plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.legend(loc=4)\n",
        "plt.suptitle('ROC Curves for Weight Optimized Random Forest')\n",
        "plt.show()\n",
        "\n",
        "#save results for iterative plotting\n",
        "result_table = result_table.append({'classifiers':'Weight Optimized Random Forest',\n",
        "                                    'fpr':fpr, \n",
        "                                    'tpr':tpr, \n",
        "                                    'auc':auc}, ignore_index=True)\n",
        "\n",
        "# 5.1.2 - Balanced Random Forests Algorithm\n",
        "##since imbalanced-learn models cannot handle NANs like XGBOOST, use an imputation method for NANs\n",
        "learning_sets = [x_train, y_train]\n",
        "for set in learning_sets:\n",
        "    set.apply(pd.to_numeric, errors = 'coerce')\n",
        "test_sets = [x_test, y_test]\n",
        "for set in test_sets:\n",
        "    set.apply(pd.to_numeric, errors = 'coerce')\n",
        "\n",
        "imp_x_train = x_train.copy(deep=True)\n",
        "imp_x_train.fillna(imp_x_train.mean(), inplace = True)\n",
        "\n",
        "imp_x_test = x_test.copy(deep=True)\n",
        "imp_x_test.fillna(imp_x_test.mean(), inplace = True)\n",
        "\n",
        "imp_y_train = y_train.copy(deep=True)\n",
        "imp_y_train.fillna(imp_y_train.mean(), inplace = True)\n",
        "imp_y_train = np.ravel(imp_y_train)\n",
        "\n",
        "imp_y_test = y_test.copy(deep=True)\n",
        "imp_y_test.fillna(imp_y_test.mean(), inplace = True)\n",
        "imp_y_test = np.ravel(imp_y_test)\n",
        "\n",
        "from imblearn.ensemble import BalancedRandomForestClassifier\n",
        "\n",
        "balanced_model = BalancedRandomForestClassifier(n_estimators=10)\n",
        "\n",
        "#evaluate the model using repeated k-fold cross validation, with three repeats and 10 folds\n",
        "cv = sklearn.model_selection.RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "#evaluate the model and collect the scores\n",
        "scores = sklearn.model_selection.cross_val_score(model, imp_x_train, imp_y_train, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
        "print('Mean ROC AUC: %.3f' % np.mean(scores))\n",
        "\n",
        "#fit the random forests model to the training data\n",
        "balanced_model.fit(imp_x_train, imp_y_train)\n",
        "\n",
        "#make predictions for test data and evaluate\n",
        "y_balanced_pred = balanced_model.predict(imp_x_test)\n",
        "balanced_accuracy = accuracy_score(imp_y_test, y_balanced_pred)\n",
        "print(\"Accuracy: %.2f%%\" % (balanced_accuracy * 100.0))\n",
        "\n",
        "#test and pred results\n",
        "#accuracy metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(imp_y_test, y_balanced_pred))\n",
        "\n",
        "#classification report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(imp_y_test, y_balanced_pred))\n",
        "\n",
        "#visualize test and pred results\n",
        "disp = sklearn.metrics.ConfusionMatrixDisplay.from_predictions(\n",
        "    imp_y_test,\n",
        "    y_balanced_pred,\n",
        "    display_labels= ['Not Deadly', 'Deadly'])\n",
        "disp.ax_.set_title('Confusion Matrix for Balanced Random Forest')\n",
        "plt.show()\n",
        "\n",
        "#visualize ROC AUC\n",
        "fpr, tpr, _ = sklearn.metrics.roc_curve(imp_y_test, y_balanced_pred)\n",
        "auc = sklearn.metrics.roc_auc_score(imp_y_test, y_balanced_pred)\n",
        "\n",
        "plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.legend(loc=4)\n",
        "plt.suptitle('ROC Curves for Balanced Random Forest')\n",
        "plt.show()\n",
        "\n",
        "#save results for iterative plotting\n",
        "result_table = result_table.append({'classifiers':'Balanced Random Forest',\n",
        "                                    'fpr':fpr, \n",
        "                                    'tpr':tpr, \n",
        "                                    'auc':auc}, ignore_index=True)\n",
        "\n",
        "#plot comparison figure\n",
        "for i in result_table.index:\n",
        "    plt.plot(result_table.loc[i]['fpr'], \n",
        "             result_table.loc[i]['tpr'], \n",
        "             label=\"{}, AUC={:.3f}\".format(result_table.loc[i]['classifiers'], result_table.loc[i]['auc']))\n",
        "    \n",
        "plt.plot([0,1], [0,1], color='grey', linestyle='--')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title('ROC Curve Analysis')\n",
        "plt.legend(loc=4)\n",
        "plt.show()\n",
        "\n",
        "# 5.2 - Logistic Regression, Model Building and Evaluation\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#since sklearn models cannot handle NANs like XGBOOST, use the imputed variables already created to deal with NANs\n",
        "#define the logistic regression model\n",
        "#account for unbalanced dataset as in XGBOOST using class_weight hyperparameter\n",
        "w = {0:2.1361, 1:97.8639}\n",
        "log_model = LogisticRegression(random_state=4, class_weight=w, max_iter=10000)\n",
        "\n",
        "#optional: hide ConvergenceWarnings for logistic regression output\n",
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
        "\n",
        "#evaluate the model using repeated k-fold cross validation, with three repeats and 10 folds\n",
        "cv = sklearn.model_selection.RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "#evaluate the model and collect the scores\n",
        "n_log_scores = sklearn.model_selection.cross_val_score(log_model, imp_x_train, imp_y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\n",
        "# report performance\n",
        "print('Mean Accuracy: %.2f (%.2f)' % (np.mean(n_log_scores), np.std(n_log_scores)))\n",
        "\n",
        "#fit the model to the training data\n",
        "log_model.fit(imp_x_train, imp_y_train)\n",
        "\n",
        "#make predictions for test data and evaluate\n",
        "y_log_pred = log_model.predict(imp_x_test)\n",
        "log_accuracy = accuracy_score(imp_y_test, y_log_pred)\n",
        "print(\"Accuracy: %.2f%%\" % (log_accuracy * 100.0))\n",
        "\n",
        "#test and pred results\n",
        "#accuracy metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(imp_y_test, y_log_pred))\n",
        "\n",
        "#classification report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(imp_y_test, y_log_pred))\n",
        "\n",
        "#visualize test and pred results\n",
        "disp = sklearn.metrics.ConfusionMatrixDisplay.from_predictions(\n",
        "    imp_y_test,\n",
        "    y_log_pred,\n",
        "    display_labels= ['Not Deadly', 'Deadly'])\n",
        "disp.ax_.set_title('Confusion Matrix for Weighted Logistic Regression')\n",
        "plt.show()\n",
        "\n",
        "#visualize ROC AUC\n",
        "fpr, tpr, _ = sklearn.metrics.roc_curve(imp_y_test, y_log_pred)\n",
        "auc = sklearn.metrics.roc_auc_score(imp_y_test, y_log_pred)\n",
        "\n",
        "plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.legend(loc=4)\n",
        "plt.suptitle('ROC Curves for Weighted Logistic Regression')\n",
        "plt.show()\n",
        "\n",
        "#save results for iterative plotting\n",
        "result_table = result_table.append({'classifiers':'Weighted Logistic Regression',\n",
        "                                    'fpr':fpr, \n",
        "                                    'tpr':tpr, \n",
        "                                    'auc':auc}, ignore_index=True)\n",
        "\n",
        "#logistic regression variable importance\n",
        "log_importance = pd.Series(log_model.coef_[0], index = imp_x_test.columns)\n",
        "log_importance = log_importance.sort_values(ascending=False)\n",
        "log_importance.nlargest(15).plot(kind = 'barh', title = 'Weighted Logistic Regression Feature Importance')\n",
        "\n",
        "# 5.3 - Naive Bayes Classifier, Model Building and Evaluation\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "#define the naive bayes model\n",
        "nb_model = GaussianNB()\n",
        "\n",
        "#evaluate the model using repeated k-fold cross validation, with three repeats and 10 folds\n",
        "cv = sklearn.model_selection.RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "#evaluate the model and collect the scores\n",
        "n_nb_scores = sklearn.model_selection.cross_val_score(nb_model, imp_x_train, imp_y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\n",
        "# report performance\n",
        "print('Mean Accuracy: %.2f (%.2f)' % (np.mean(n_nb_scores), np.std(n_nb_scores)))\n",
        "\n",
        "#fit the model to the training data\n",
        "nb_model.fit(imp_x_train, imp_y_train)\n",
        "\n",
        "#make predictions for test data and evaluate\n",
        "y_nb_pred = nb_model.predict(imp_x_test)\n",
        "nb_accuracy = accuracy_score(imp_y_test, y_nb_pred)\n",
        "print(\"Accuracy: %.2f%%\" % (nb_accuracy * 100.0))\n",
        "\n",
        "#test and pred results\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(imp_y_test, y_nb_pred))\n",
        "\n",
        "#visualize test and pred results\n",
        "disp = sklearn.metrics.ConfusionMatrixDisplay.from_predictions(\n",
        "    imp_y_test,\n",
        "    y_nb_pred,\n",
        "    display_labels= ['Not Deadly', 'Deadly'])\n",
        "disp.ax_.set_title('Confusion Matrix for Naive Bayes')\n",
        "plt.show()\n",
        "\n",
        "#visualize ROC AUC\n",
        "fpr, tpr, _ = sklearn.metrics.roc_curve(imp_y_test, y_nb_pred)\n",
        "auc = sklearn.metrics.roc_auc_score(imp_y_test, y_nb_pred)\n",
        "\n",
        "plt.plot(fpr,tpr,label=\"AUC=\"+str(auc))\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.legend(loc=4)\n",
        "plt.suptitle('ROC Curves for Naive Bayes')\n",
        "plt.show()\n",
        "\n",
        "#save results for iterative plotting\n",
        "result_table = result_table.append({'classifiers':'Naive Bayes',\n",
        "                                    'fpr':fpr, \n",
        "                                    'tpr':tpr, \n",
        "                                    'auc':auc}, ignore_index=True)\n",
        "\n",
        "# 5.4 - Consolidated Evaluation of Models\n",
        "\n",
        "#plot comparison figure\n",
        "for i in result_table.index:\n",
        "    plt.plot(result_table.loc[i]['fpr'], \n",
        "             result_table.loc[i]['tpr'], \n",
        "             label=\"{}, AUC={:.3f}\".format(result_table.loc[i]['classifiers'], result_table.loc[i]['auc']))\n",
        "    \n",
        "plt.plot([0,1], [0,1], color='grey', linestyle='--')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title('ROC Curve Analysis')\n",
        "plt.legend(loc=4)\n",
        "plt.show()\n",
        "\n",
        "#store validation results in variables\n",
        "results = []\n",
        "results.append(n_scores)\n",
        "results.append(n_log_scores)\n",
        "results.append(n_nb_scores)\n",
        "\n",
        "model_names = ['Random Forests', 'Logistic Regression', 'Naive Bayes']\n",
        "\n",
        "#plot results to boxplot\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Comparison of Algorithm Accuracy')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(model_names)\n",
        "plt.show()\n"
      ]
    }
  ]
}